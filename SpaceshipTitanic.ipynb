{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#import tensorflow_decision_forests as tfdf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "outputs": [],
   "source": [
    "# read test file\n",
    "testSet = pd.read_csv('./test.csv')\n",
    "\n",
    "IDColforConcat = testSet[[\"PassengerId\"]]\n",
    "\n",
    "testSet[[\"Deck\", \"Cabin_Nr\", \"Side\"]] = testSet[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "\n",
    "# remove potentially misleading or irrelevant columns\n",
    "testSet = testSet.drop(['PassengerId' , 'Name', 'Cabin'], axis=1)\n",
    "#y_testTargetCol = testSet[\"Transported\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "outputs": [],
   "source": [
    "# read training file\n",
    "trainingSet = pd.read_csv('./train.csv')\n",
    "\n",
    "# extrapolate target column\n",
    "y_targetCol = trainingSet[\"Transported\"]\n",
    "\n",
    "# split Cabin column into three: Deck - Cabin_Nr - Side\n",
    "trainingSet[[\"Deck\", \"Cabin_Nr\", \"Side\"]] = trainingSet[\"Cabin\"].str.split(\"/\", expand=True)\n",
    "\n",
    "# remove potentially misleading or irrelevant columns\n",
    "trainingSet = trainingSet.drop(['PassengerId' , 'Name', 'Cabin', 'Transported'], axis=1)\n",
    "\n",
    "#debugging option\n",
    "# print(trainingSet)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "outputs": [],
   "source": [
    "# get target column and shorten set-variablename\n",
    "y = y_targetCol;\n",
    "x = trainingSet;\n",
    "\n",
    "# split training data for evaluation into a fitting part (used to train the algorithm) and the part that can be tested against to find out accuracy\n",
    "xtrain, xtest,ytrain, ytest = train_test_split(x,y, test_size=0.3, random_state=666)\n",
    "\n",
    "\n",
    "\n",
    "# categorical_feature: ist es ein numerisches (aka zahlen) oder ein kategorisches feature\n",
    "ml_est = HistGradientBoostingClassifier(categorical_features=[True, False, True, False, False,False,False,False,False,False,True,False,True]);\n",
    "ml_est.fit(xtrain,ytrain);\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "outputs": [],
   "source": [
    " # y = df_train_full[\"SalePrice\"]\n",
    " #    X = df_train_full.drop(columns=[\"SalePrice\", \"Id\"])\n",
    " #    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)\n",
    " #\n",
    " #    ml_est = training(X_train, np.log(y_train))\n",
    " #    train_evaluation(ml_est, X_test, y_test)\n",
    " #\n",
    " #    ml_est = training(X, np.log(y))\n",
    " #    yhat_train_full = train_evaluation(ml_est, X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [],
   "source": [
    "yhat = ml_est.predict(xtest)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8194018404907976"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ytest, yhat)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [],
   "source": [
    "y_test_fin = ml_est.predict(testSet)\n",
    "# y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "# put columns together PassengerID and prediction of transport\n",
    "#submission = pd.concat([IDColforConcat, y_test], axis=1)\n",
    "#submission"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
